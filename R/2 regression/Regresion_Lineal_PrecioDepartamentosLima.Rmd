---
title: "Regresion Lineal"
author: "CARLOS ALEX NINA GUARDAPUCLLA"
date: "2022-11-28"
output: html_document
---

## <b style = 'color : green;'>IMPORTACION DE BIBLIOTECAS</b>

```{r}
library(tidyverse)
library(tidyr)
library(dplyr)
library(DataExplorer)
library(mice)
library(GGally)
library(scales)
library(psych)
library(corrplot)
```
Leer dataset
```{r}
df <- read.csv("datos/precios_venta_alquiler_depa.csv", stringsAsFactors = TRUE)
head(df)
```

mostrar dimensiones del dataset
```{r}
dim(df)
```

verificar tipos de datos contenidos en el dataset
```{r}
str(df)
```

resumen estadístico
```{r}
summary(df)
```


Visualización de datos

- histograma
```{r}
plot_histogram(df)
```
Eliminar filas y/o columnas poco relevantes

- Conservar solo los datos de ventas
```{r}
df_venta <- df[!(df$Tipo == 'alquiler'),]
df_venta <- df_venta[,-c(1)] 
head(df_venta)
```

verificar tipos de datos contenidos en el nuevo dataset
```{r}
str(df_venta)
```

mostrar dimensiones del nuevo dataset
```{r}
dim(df_venta)
```

resumen estadístico de ventas
```{r}
summary(df_venta)
```

verificar si existen datos nulos
```{r}
sum(is.na(df_venta))
```

Busqueda de outliers

- diagrama de boxplot
```{r}
boxplot(df_venta)
```
Tratamiento de outliers

```{r}
tratamiento_outliers <- function(df,colum){
  
  qrts <- quantile(df[colum], probs = c(0.25, 0.75), na.rm = TRUE)
  caps <- quantile(df[colum], probs = c(.05, .95), na.rm = TRUE)
  iqr <- qrts[2]-qrts[1]
  h <- 1.5 * iqr
  #df[colum][df[colum]<qrts[1]-h] <- caps[1]
  #df[colum][df[colum]>qrts[2]+h] <- caps[2]
  
  # reemplazando por la mediana
  df[colum][df[colum]<qrts[1]-h] <- mean(df[[colum]])
  df[colum][df[colum]>qrts[2]+h] <- mean(df[[colum]])
  
  
  return(df)
}
```


crear una copia de los datos
```{r}
df_sin_outlier <- df_venta
```

aplicar la funcion sobre todas las columnas


- eliminar outliers
```{r}
for (name in seq_along(df_sin_outlier)){
  df_sin_outlier <- tratamiento_outliers(df_sin_outlier, name)
}
```

dataset después del tratamiento de outliers
```{r}
boxplot(df_sin_outlier)
```


resumen estadístico
```{r}
summary(df_sin_outlier)
```


## <b style = 'color : green;'>PREPROCESAMIENTO DE DATOS</b>

reescalando los valores
```{r}
scaled_data <- as.data.frame(scale(df_sin_outlier))
head(df_scaled)
```
```{r}
sum(is.na(df_sin_outlier))
str(df_sin_outlier)
```


```{r}
sum(is.na(scaled_data))
```


correlacion lineal
```{r}
pairs.panels(scaled_data,
             method = "spearman",
             density=FALSE,
             ellipses=FALSE,
             smooth = FALSE)
```
matriz de correlación
```{r}
plot_correlation(scaled_data)
```
```{r}
corrplot(cor(scaled_data),        # Matriz de correlación
         method = "number", # Método para el gráfico de correlación
         type = "full",    # Estilo del gráfico (también "upper" y "lower")
         diag = TRUE,      # Si TRUE (por defecto), añade la diagonal
         tl.col = "black", # Color de las etiquetas
         bg = "white",     # Color de fondo
         title = "",       # Título
         col = NULL)       # Paleta de colores
```

Extraer solo las  columnas "Precio y Superficie"
```{r}
df_scaled <- scaled_data[,c(1,2)]
head(df_scaled)
```


Dividir los datos
```{r}
#install.packages("caret", dependencies = c("Depends", "Suggests"))
```

```{r}
library(caret)
```

```{r}
set.seed(123)
# Se crean los índices de las observaciones de entrenamiento
train_index <- createDataPartition(y = df_scaled$Precio.en.soles.corrientes, p = 0.8, list = FALSE, times = 1)
datos_train <- df_scaled[train_index, ]
datos_test  <- df_scaled[-train_index, ]
```

```{r}
dim(datos_train)
```


verificar la distribucion de entrenamiento de la variable respuesta
```{r}
dim(prop.table(table(datos_train$Precio.en.soles.corrientes)))
```
verificar la distribucion de prueba de la variable respuesta
```{r}
dim(prop.table(table(datos_test$Precio.en.soles.corrientes)))
```

Regresion lineal simple


- Cálculo y representacion de la recta de mínimos cuadrados

  - fit (precio y superficie)
```{r}
# lm(variable dependiente y ~ variable independiente x, dataset)
modelo_regresion <- lm(Precio.en.soles.corrientes ~ Superficie, data = datos_train, na.action = na.exclude)
```

# informacion del modelo
```{r}
summary(modelo_regresion)
```

graficar los resultados del modelo entrenado
```{r}
ggplot(datos_train, aes(x=Superficie, y=Precio.en.soles.corrientes)) + 
  geom_point() +
  geom_smooth(method='lm', formula=y~x, se=FALSE, col='dodgerblue1') +
  theme_light()
```

intervalo de confianza
```{r}
confint(lm(formula = Precio.en.soles.corrientes ~ Superficie , data = datos_train))
```

crear un vector de predicciones basado en el propio conjunto de entrenamiento
```{r}
y_predict <- predict(modelo_regresion, datos_train)
```

realizar predicciones sobre el conjunto de validación
```{r}
y_test_predict <- predict(modelo_regresion, datos_test)
```

construir la gráfica con los resultados de la predicción
```{r}
ggplot() + geom_point(data = datos_test, aes(x = Superficie, y = Precio.en.soles.corrientes), size = 0.9) + 
  geom_line(aes( x = datos_test$Superficie, y = y_test_predict), color = "red") +
  xlab("Variable Independiente") + 
  ylab("Variable Dependiente") + 
  ggtitle("Curva de Ajuste sobre Conjunto de Entrenamiento")
```

# METRICAS DE EVALUACION

correlación existente entre los valores del conjunto de entrenamiento, y los valores predichos para dicho conjunto
```{r}
cor(datos_train$Precio.en.soles.corrientes, y_predict)
```

correlación existente entre los valores del conjunto de prueba, y los valores predichos para dicho conjunto
```{r}
cor(datos_test$Precio.en.soles.corrientes, y_test_predict)
```


```{r}
objeto <- Precio.en.soles.corrientes ~ Superficie
```

bootstrap
```{r}
# define trining control
set.seed(123)
metodo_boot <- trainControl(method = "boot", number = 100)

# fit a regresion model
model_boot <- train(objeto, 
                    data = datos_test,
                    method = "lm",
                    trControl = metodo_boot)

print(model_boot)
```


metodo de validacion cruzada
```{r}
# define trining control
set.seed(123)
metodo_cv <- trainControl(method = "cv", number = 100)

# fit a regresion model
model_cv <- train(objeto, 
                    data = datos_test,
                    method = "lm",
                    trControl = metodo_cv)

print(model_cv)
```


metodo LOOCV
```{r}
# define trining control
set.seed(123)
metodo_LOOVC <- trainControl(method = "LOOCV")

# fit a regresion model
model_LOOVC <- train(objeto, 
                    data = datos_test,
                    method = "lm",
                    trControl = metodo_LOOVC)

print(model_LOOVC)
```

METODO DE VALIDACION REPETIDA
```{r}
# define trining control
set.seed(123)
metodo_repeatedcv <- trainControl(method = "repeatedcv", repeats = 10)

# fit a regresion model
model_repeatedcv <- train(objeto, 
                    data = datos_test,
                    method = "lm",
                    trControl = metodo_repeatedcv)

print(model_repeatedcv)
```

